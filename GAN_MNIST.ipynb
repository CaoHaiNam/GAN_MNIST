{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaoHaiNam/Nam3/blob/master/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSrDCw7YTCnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UrD8MqYlPRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-processing\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test  = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test  = X_test.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAK1yGiclvrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dim of noise vector\n",
        "z_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLPyBTOtl6R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optimizer\n",
        "adam = Adam(lr=0.0002, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maThj3oSQ3Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator model\n",
        "g = Sequential()\n",
        "g.add(Dense(256, input_dim = z_dim, activation = LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(512, activation = LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(1024, activation = LeakyReLU(alpha=0.2)))\n",
        "# sigmoid, because data was nolmalized\n",
        "g.add(Dense(784, activation='sigmoid'))\n",
        "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "g.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdcBJ0GnSxdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator model\n",
        "d = Sequential()\n",
        "d.add(Dense(1024, input_dim = 784, activation = LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(512, activation = LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(256, activation = LeakyReLU(0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(1, activation = 'sigmoid'))\n",
        "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "d.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLClxpQWTmyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.trainable = False\n",
        "inputs = Input(shape=(z_dim, ))\n",
        "hidden = g(inputs)\n",
        "output = d(hidden)\n",
        "gan = Model(inputs, output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam, mareics = ['accuracy'])\n",
        "gan.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02vSsczbaBR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# draw loss function\n",
        "def plot_loss(losses):\n",
        "  d_loss = [v[0] for v in losses[\"D\"]]\n",
        "  g_loss = [v[0] for v in losses[\"G\"]]\n",
        "\n",
        "  plt.figure(figsize = (10,8))\n",
        "  plt.plot(d_loss, label='Discriminator loss')\n",
        "  plt.plot(g_loss, label='Generator loss')\n",
        "\n",
        "  plt.xlabel('Epoches')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iztxnHI7b_0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function drawing sample from Generator\n",
        "def plot_generated(n_ex=10, dim=(1, 10), figsize=(12, 2)):\n",
        "  noise = np.random.normal(0, 1, zise = (n_ex, z_dim))\n",
        "  generated_images = g.predict(noise)\n",
        "  generated_images = generated_images.reshape(n_ex, 28, 28)\n",
        "\n",
        "  plt.figure(figsize = figsize)\n",
        "  for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(dim[0], dim[1], i+1)\n",
        "    plt.imshow(generated_images[i], interpolation = 'nearest', cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-qSxGWewjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store loss and accuracy of D and G\n",
        "losses = {\"D\":[], \"G\":[]}\n",
        "\n",
        "def train(epoches=1, plt_frq=1, BATCH_SIZE=128):\n",
        "  #the amount of running times per epoch\n",
        "  batchCount = int(X_train.shape[0]/ BATCH_SIZE)\n",
        "  print('Epochs: ', epochs)\n",
        "  print('Batch size: ', BATCH_SIZE)\n",
        "  print('Batches per epoch:', batchCount)\n",
        "\n",
        "  for e in tqdm_notebook(range(1, epoches + 1)):\n",
        "    if e == 1 or e%plt_frq == 0:\n",
        "      print('-'*15, 'Epoch %d' %e, '-'*15)\n",
        "      for _ in range(batchCount):\n",
        "        # select radom pics in MNIST dataset(real pics)\n",
        "        image_batch = X_train[np.random.randint(0, X_train.shapw[0], size=BATCH_SIZE)]\n",
        "        # create random noise\n",
        "        noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "\n",
        "        # use G generate pics by noise\n",
        "        generated_images = g.predict(noise)\n",
        "        X = np.concatenate((image_batch, generated_images))\n",
        "\n",
        "        # create label\n",
        "        y = np.zeros(2*BATCH_SIZE)\n",
        "        y[:BATCH_SIZE] = 0.9 #\n",
        "\n",
        "        # train D\n",
        "        d.trainable = True\n",
        "        d_loss = d.train_on_batch(X, y)\n",
        "\n",
        "        # train G\n",
        "        noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "        # while train G, assign label equals 1 for pic which were generated by G, trying to trick D\n",
        "        y2 = np.ones(BATCH_SIZE)\n",
        "        # train G, stoping updating D paras\n",
        "        d.trainable = False\n",
        "        g_loss = gan.train_on_batch(noise, y2)\n",
        "\n",
        "        # store loss function\n",
        "      losses['D'].append(d_loss)\n",
        "      losses['G'].append(g_loss)\n",
        "\n",
        "        # visualize result\n",
        "      if e == 1 or e%plt_frq == 0:\n",
        "        plot_generated()\n",
        "  plot_loss(losses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSP1gBi8ncg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(epoches=200, plt_frq=20, BATCH_SIZE=128)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}